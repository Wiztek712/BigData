{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "import pandas as pd\n",
    "from download import download_data_and_parse_it\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 23\n",
    "learning_rate = 0.001\n",
    "# learning_rate = 0.001168\n",
    "num_epochs = 10\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "The file exists.\n",
      "[['apple' 0]\n",
      " ['banana' 1]\n",
      " ['bench' 2]\n",
      " ['bicycle' 3]\n",
      " ['car' 4]\n",
      " ['cat' 5]\n",
      " ['dog' 6]\n",
      " ['elbow' 7]\n",
      " ['fish' 8]\n",
      " ['guitar' 9]\n",
      " ['hammer' 10]\n",
      " ['house' 11]\n",
      " ['ice cream' 12]\n",
      " ['moon' 13]\n",
      " ['pencil' 14]\n",
      " ['sailboat' 15]\n",
      " ['star' 16]\n",
      " ['sword' 17]\n",
      " ['t-shirt' 18]\n",
      " ['tent' 19]\n",
      " ['tree' 20]\n",
      " ['umbrella' 21]\n",
      " ['wine bottle' 22]]\n",
      "size of datasets array : 23\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "datasets = [\n",
    "        \"star\", \"sword\", \"tent\", \"apple\", \"banana\", \"cat\", \n",
    "        \"dog\", \"car\", \"house\", \"tree\", \"guitar\", \"bicycle\", \"wine bottle\", \"bench\", \"pencil\",\n",
    "        \"elbow\", \"t-shirt\", \"hammer\", \"moon\", \"umbrella\", \"ice cream\", \"sailboat\", \"fish\"\n",
    "    ]\n",
    "    \n",
    "all_dfs = []  # List to store all DataFrames\n",
    "for dataset in datasets:\n",
    "    file_path = os.path.join(\"data\", f\"{dataset}.ndjson\")\n",
    "    dataset_df = download_data_and_parse_it(file_path)\n",
    "    all_dfs.append(dataset_df)\n",
    "# Combine all datasets\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Assign class labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['class'] = le.fit_transform(df['word'])\n",
    "\n",
    "word_class_mapping = df[['word', 'class']].drop_duplicates().sort_values('class').to_numpy()\n",
    "\n",
    "# Display the array\n",
    "print(word_class_mapping)\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42)  # 60% train, 40% temp\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)  # Split temp into 20% val, 20% test\n",
    "\n",
    "print(\"size of datasets array :\", len(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>recognized</th>\n",
       "      <th>key_id</th>\n",
       "      <th>drawing</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>star</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-03-07 16:39:23.36509 UTC</td>\n",
       "      <td>True</td>\n",
       "      <td>5260413706960896</td>\n",
       "      <td>[[[67, 37, 30, 44, 70, 105, 116, 184, 192, 194...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>star</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-03-15 15:13:18.18952 UTC</td>\n",
       "      <td>True</td>\n",
       "      <td>4853913289228288</td>\n",
       "      <td>[[[104, 106, 115, 125, 129, 143, 156], [108, 7...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>star</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-03-15 23:06:33.26227 UTC</td>\n",
       "      <td>True</td>\n",
       "      <td>4624556264259584</td>\n",
       "      <td>[[[19, 101, 172, 209, 224, 223, 206, 141, 19, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-27 14:04:41.8484 UTC</td>\n",
       "      <td>True</td>\n",
       "      <td>4729612393250816</td>\n",
       "      <td>[[[103, 142, 148, 166, 216, 255, 226, 163], [6...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>star</td>\n",
       "      <td>US</td>\n",
       "      <td>2017-03-23 16:08:34.73471 UTC</td>\n",
       "      <td>True</td>\n",
       "      <td>5130650279477248</td>\n",
       "      <td>[[[130, 86, 75, 64, 62, 68, 135, 137, 142, 161...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word countrycode                      timestamp  recognized  \\\n",
       "0  star          US  2017-03-07 16:39:23.36509 UTC        True   \n",
       "1  star          US  2017-03-15 15:13:18.18952 UTC        True   \n",
       "2  star          US  2017-03-15 23:06:33.26227 UTC        True   \n",
       "3  star          US   2017-01-27 14:04:41.8484 UTC        True   \n",
       "4  star          US  2017-03-23 16:08:34.73471 UTC        True   \n",
       "\n",
       "             key_id                                            drawing  class  \n",
       "0  5260413706960896  [[[67, 37, 30, 44, 70, 105, 116, 184, 192, 194...     16  \n",
       "1  4853913289228288  [[[104, 106, 115, 125, 129, 143, 156], [108, 7...     16  \n",
       "2  4624556264259584  [[[19, 101, 172, 209, 224, 223, 206, 141, 19, ...     16  \n",
       "3  4729612393250816  [[[103, 142, 148, 166, 216, 255, 226, 163], [6...     16  \n",
       "4  5130650279477248  [[[130, 86, 75, 64, 62, 68, 135, 137, 142, 161...     16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Vector-To-Image Algorithm - Drawing-to-image changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class QuickDrawDataset(Dataset):\n",
    "    def __init__(self, drawings, labels, resize_to=(64, 64)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            drawings (list or array): List of drawing data (tensor or numpy arrays).\n",
    "            labels (list or array): List of class labels corresponding to each drawing.\n",
    "            resize_to (tuple): Target size for resizing the image.\n",
    "        \"\"\"\n",
    "        self.drawings = drawings\n",
    "        self.labels = labels\n",
    "        self.resize_to = resize_to  # Tuple (width, height)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.drawings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert the drawing format to image\n",
    "        drawing = self.drawings.iloc[idx] if isinstance(self.drawings, pd.Series) else self.drawings[idx]\n",
    "        image = self.drawing_to_image(drawing)\n",
    "        label = self.labels.iloc[idx] if isinstance(self.labels, pd.Series) else self.labels[idx]\n",
    "        \n",
    "        # Convert the image to a tensor and add batch dimension\n",
    "        image_tensor = torch.FloatTensor(image).unsqueeze(0)\n",
    "        return image_tensor, label\n",
    "\n",
    "    def drawing_to_image(self, drawing):\n",
    "        img_size = 64\n",
    "        image = np.zeros((512, 512), dtype=np.uint8)\n",
    "        \n",
    "        all_x, all_y = [], []\n",
    "        \n",
    "        for stroke in drawing:\n",
    "            all_x.extend(stroke[0])\n",
    "            all_y.extend(stroke[1])\n",
    "\n",
    "        # print(\"all_x : \", all_x)\n",
    "        # print(\"all_y : \",all_y)\n",
    "\n",
    "        if not all_x or not all_y:\n",
    "            return image  # Return blank if no valid drawing data\n",
    "\n",
    "        # Find bounding box\n",
    "        x_min, x_max = min(all_x), max(all_x)\n",
    "        y_min, y_max = min(all_y), max(all_y)\n",
    "\n",
    "        # print(\"max_x : \", x_max, \" min_x : \", x_min)\n",
    "        # print(\"max_y : \", y_max, \" min_y : \", y_min)\n",
    "\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        longest_side = max(width, height)\n",
    "\n",
    "        # print(\"longest_side : \", longest_side)\n",
    "\n",
    "        # Compute center of drawing\n",
    "        x_center = (x_max + x_min) / 2\n",
    "        y_center = (y_max + y_min) / 2\n",
    "\n",
    "        # Compute new square bounds while keeping it within 256x256\n",
    "        half_size = longest_side / 2\n",
    "        x_start = max(0, min(512 - longest_side, int(x_center - half_size)))\n",
    "        y_start = max(0, min(512 - longest_side, int(y_center - half_size)))\n",
    "        x_end = min(512, x_start + longest_side)\n",
    "        y_end = min(512, y_start + longest_side)\n",
    "\n",
    "        # Normalize strokes within the centered bounding box\n",
    "        for stroke in drawing:\n",
    "            x_coords = np.array(stroke[0])\n",
    "            y_coords = np.array(stroke[1])\n",
    "\n",
    "            # Shift points to align with the new bounding box\n",
    "            x_coords = np.clip(x_coords - (x_center - half_size), 0, longest_side - 1)\n",
    "            y_coords = np.clip(y_coords - (y_center - half_size), 0, longest_side - 1)\n",
    "\n",
    "            for i in range(len(x_coords) - 1):\n",
    "                x1, y1 = int(x_coords[i]), int(y_coords[i])\n",
    "                x2, y2 = int(x_coords[i + 1]), int(y_coords[i + 1])\n",
    "\n",
    "                # Draw the strokes on the image\n",
    "                if 0 <= x1 < longest_side and 0 <= y1 < longest_side:\n",
    "                    image[y1 + y_start, x1 + x_start] = 255\n",
    "                if 0 <= x2 < longest_side and 0 <= y2 < longest_side:\n",
    "                    image[y2 + y_start, x2 + x_start] = 255\n",
    "\n",
    "        # Extract the centered square region\n",
    "        cropped_image = image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Resize to 64x64\n",
    "        pil_image = Image.fromarray(cropped_image)\n",
    "        pil_image = pil_image.resize((img_size, img_size), Image.Resampling.LANCZOS)\n",
    "\n",
    "        return np.array(pil_image)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f1be69ede50>\n"
     ]
    }
   ],
   "source": [
    "# # Create datasets\n",
    "# train_dataset = QuickDrawDataset(train_df['drawing'], train_df['class'])\n",
    "# val_dataset = QuickDrawDataset(val_df['drawing'], val_df['class'])\n",
    "# test_dataset = QuickDrawDataset(test_df['drawing'], test_df['class'])\n",
    "\n",
    "# # Create DataLoaders\n",
    "# from torch.utils.data import DataLoader\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the datasets with resizing\n",
    "train_dataset = QuickDrawDataset(train_df['drawing'], train_df['class'], resize_to=(64, 64))\n",
    "val_dataset = QuickDrawDataset(val_df['drawing'], val_df['class'], resize_to=(64, 64))\n",
    "test_dataset = QuickDrawDataset(test_df['drawing'], test_df['class'], resize_to=(64, 64))\n",
    "# Create DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32  # Example batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to visualize some entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drawing = train_dataset.__getitem__(260000) #Car\n",
    "drawing = train_dataset.__getitem__(270014)\n",
    "\n",
    "# print(drawing)\n",
    "import matplotlib.pyplot as plt\n",
    "print(drawing[0].shape)\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(drawing[0].squeeze(), cmap='gray')  # Squeeze to remove the single channel dimension\n",
    "plt.axis('off')  # Hide axis for better visualization\n",
    "plt.title(drawing[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example input data (simplified vector data from the NDJSON)\n",
    "drawings = [\n",
    "    [[[4,18,29,63,93,120,146,169,186,218,244,234,186,154,128,86,44,14,0],[7,51,66,90,101,106,106,101,93,67,22,23,49,58,59,53,26,16,6]],[[10,27,42,78,135,162,212,230,244],[15,39,53,67,80,74,48,35,20]],[[9,2,16,22,23,20],[18,3,0,3,8,20]],[[229,244,254,252,241],[23,17,18,22,30]],[[52,52],[52,52]],[[52,50],[52,52]],[[59,43],[69,61]]],\n",
    "    [[[223,226,227,233,254,255,248,227],[35,25,2,0,2,21,27,30]],[[234,235,244,246,249],[4,8,12,19,20]],[[232,208,168,135,98,37],[28,51,104,138,164,196]],[[255,255,245,194,182,172,115,26,18,8],[25,61,106,199,213,217,219,235,235,230]],[[12,1,0,0,10,22,29,28,16,11],[193,191,194,206,219,218,206,199,194,197]],[[41,29,12],[232,228,217]],[[7,7,12,14,14,18,19,23,27,29,37],[186,199,190,193,209,200,204,204,194,203,192]],[[230,230,235,238,241,245,245],[8,15,8,17,16,4,11]],[[251,251,241,235,211,191,121,59,31],[26,69,113,126,155,168,200,215,215]],[[214,201,177,153,120,108],[72,102,131,152,167,175]]], \n",
    "    [[[2,0,4,24,41,94,160,186,189,177,151,134,94,71,30],[0,38,79,138,162,207,247,255,251,238,218,200,139,98,45]]]\n",
    "]\n",
    "\n",
    "# Reconstruct the image from the simplified drawing\n",
    "index = 0\n",
    "for drawing in drawings:\n",
    "    reconstructed_image = train_dataset.drawing_to_image(drawing)\n",
    "    index+=1\n",
    "    # Display the image\n",
    "    plt.imshow(reconstructed_image, cmap='gray')\n",
    "    plt.title(index)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just a resizing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming `drawing` is the tuple as described\n",
    "image_tensor = drawing[0]  # Image tensor of shape (1, H, W)\n",
    "label = drawing[1]         # The label (in this case, 3)\n",
    "\n",
    "image_numpy = image_tensor.squeeze().cpu().numpy()  # Shape: (H, W)\n",
    "image_pil = Image.fromarray((image_numpy * 255).astype(np.uint8))  # Convert to uint8 image\n",
    "\n",
    "# Resize using PIL\n",
    "resized_image_pil = image_pil.resize((64, 64), Image.Resampling.LANCZOS)\n",
    "\n",
    "# Convert back to NumPy (optional)\n",
    "resized_image_numpy = np.array(resized_image_pil) / 255.0  # Normalize\n",
    "\n",
    "# Plot original and resized image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original image\n",
    "ax[0].imshow(image_numpy, cmap='gray')\n",
    "ax[0].set_title(f\"Original Image (256x256), Label: {label}\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Resized image\n",
    "ax[1].imshow(resized_image_numpy, cmap='gray')\n",
    "ax[1].set_title(\"Resized Image (64x64)\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, optimizer, criterion):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):  # Number of epochs\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Testing loop\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 16*16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "model structure SimpleCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8192, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=128, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1, Loss: 0.36464114999882846\n",
      "Epoch 2, Loss: 0.2793513868731312\n",
      "Epoch 3, Loss: 0.24580231722231982\n",
      "Epoch 4, Loss: 0.22004315000631153\n",
      "Epoch 5, Loss: 0.1977394068515854\n",
      "Epoch 6, Loss: 0.17850245226462413\n",
      "Epoch 7, Loss: 0.16114098512334682\n",
      "Epoch 8, Loss: 0.14693802749813806\n",
      "Epoch 9, Loss: 0.1344156533942808\n",
      "Epoch 10, Loss: 0.12360996715897243\n",
      "Accuracy: 89.78%\n",
      "Execution time: 13298.465192 seconds\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "print(next(model.parameters()).device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"model structure\", model)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_model(model, optimizer, criterion)\n",
    "test_model(model)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to simple_model64.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "model_file_path = \"simple_model64.pth\"\n",
    "torch.save(model.state_dict(), model_file_path)\n",
    "print(f\"Model saved to {model_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightModel structure EfficientCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=12, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightModel structure\u001b[39m\u001b[38;5;124m\"\u001b[39m, lightModel)\n\u001b[1;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m test_model(lightModel)\n\u001b[1;32m     34\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):  \u001b[38;5;66;03m# Number of epochs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36mQuickDrawDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Convert the drawing format to image\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     drawing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawings\u001b[38;5;241m.\u001b[39miloc[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawings, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawings[idx]\n\u001b[0;32m---> 24\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawing_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrawing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39miloc[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Convert the image to a tensor and add batch dimension\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m, in \u001b[0;36mQuickDrawDataset.drawing_to_image\u001b[0;34m(self, drawing)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Resize the image to the desired size (64x64)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(image)  \u001b[38;5;66;03m# Convert to PIL Image\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m \u001b[43mpil_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLANCZOS\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Resize image\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Convert back to numpy array\u001b[39;00m\n\u001b[1;32m     61\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pil_image)\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/PIL/Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2357\u001b[0m         )\n\u001b[1;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2363\u001b[0m         )\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class EfficientCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # 1 input channel, 16 filters\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 # Reduce size by half\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 16 * 16, 64),  # Fewer neurons in FC layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "lightModel = EfficientCNN(num_classes).to(device)\n",
    "optimizer = optim.Adam(lightModel.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"lightModel structure\", lightModel)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_model(lightModel, optimizer, criterion)\n",
    "test_model(lightModel)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightModel structure EnhancedCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4096, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=23, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, SGD, RMSprop\n",
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),  # Normalize feature maps for faster convergence\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # Add a third convolutional layer\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 256),  # More neurons for higher capacity\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Add dropout for regularization\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "deepModel = EnhancedCNN().to(device)\n",
    "# optimizer = optim.Adam(deepModel.parameters(), lr=learning_rate)\n",
    "optimizer = SGD(deepModel.parameters(), lr=learning_rate, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"lightModel structure\", deepModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-12 17:16:25,261] A new study created in memory with name: no-name-cd9e1b50-210a-47c3-bbee-a32ad2accb09\n",
      "/tmp/ipykernel_1648/4058461976.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-4, 1e-2)\n",
      "[I 2025-02-12 18:47:15,247] Trial 0 finished with value: -7349.272308028303 and parameters: {'learning_rate': 0.003980904145188189, 'optimizer': 'SGD'}. Best is trial 0 with value: -7349.272308028303.\n",
      "[I 2025-02-12 20:10:22,363] Trial 1 finished with value: -10277.886927314103 and parameters: {'learning_rate': 0.0006821257345600005, 'optimizer': 'RMSprop'}. Best is trial 0 with value: -7349.272308028303.\n",
      "[I 2025-02-12 21:44:05,513] Trial 2 finished with value: -7218.030352943577 and parameters: {'learning_rate': 0.00012022160650979998, 'optimizer': 'Adam'}. Best is trial 2 with value: -7218.030352943577.\n",
      "[I 2025-02-12 23:17:11,004] Trial 3 finished with value: -7353.486540636048 and parameters: {'learning_rate': 0.004353557432077811, 'optimizer': 'SGD'}. Best is trial 2 with value: -7218.030352943577.\n",
      "[I 2025-02-13 00:50:07,912] Trial 4 finished with value: -7100.132679652423 and parameters: {'learning_rate': 0.0011682692580404393, 'optimizer': 'SGD'}. Best is trial 4 with value: -7100.132679652423.\n",
      "[I 2025-02-13 02:24:19,457] Trial 5 finished with value: -129892.28690338135 and parameters: {'learning_rate': 0.007382843205866382, 'optimizer': 'RMSprop'}. Best is trial 4 with value: -7100.132679652423.\n",
      "[I 2025-02-13 03:58:39,911] Trial 6 finished with value: -12297.710491381586 and parameters: {'learning_rate': 0.0033208411407991065, 'optimizer': 'Adam'}. Best is trial 4 with value: -7100.132679652423.\n",
      "[I 2025-02-13 05:32:38,253] Trial 7 finished with value: -7324475.926270485 and parameters: {'learning_rate': 0.007492861550871873, 'optimizer': 'Adam'}. Best is trial 4 with value: -7100.132679652423.\n",
      "[I 2025-02-13 07:06:19,926] Trial 8 finished with value: -8062.942795170471 and parameters: {'learning_rate': 0.00021441064700209453, 'optimizer': 'RMSprop'}. Best is trial 4 with value: -7100.132679652423.\n",
      "[I 2025-02-13 08:39:24,300] Trial 9 finished with value: -7432.894228035584 and parameters: {'learning_rate': 0.005850550533210029, 'optimizer': 'SGD'}. Best is trial 4 with value: -7100.132679652423.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0011682692580404393, 'optimizer': 'SGD'}\n",
      "-7100.132679652423\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", 0.001, 0.0005)\n",
    "    momentum = trial.suggest_categorical=[\"momentum\", 0.9, 0.99, 0.5]\n",
    "    \n",
    "    # Initialize model\n",
    "    model = EnhancedCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    # Training loop (simplified for Optuna)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Use a small number of epochs for quick evaluation\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluation (simplified, using validation loss as metric)\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return -total_loss  # Minimize validation loss\n",
    "\n",
    "# Run Optuna Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=6)\n",
    "\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-13 12:39:18,413] A new study created in memory with name: no-name-3e8ff54f-e8e4-49a7-9f72-29b3f977d77f\n",
      "[I 2025-02-13 14:13:30,850] Trial 0 finished with value: -7236.1364429099485 and parameters: {'learning_rate': 0.0005, 'momentum': 0.9}. Best is trial 0 with value: -7236.1364429099485.\n",
      "[I 2025-02-13 15:45:33,800] Trial 1 finished with value: -7302.914536266588 and parameters: {'learning_rate': 0.0005, 'momentum': 0.9}. Best is trial 0 with value: -7236.1364429099485.\n",
      "[W 2025-02-13 16:45:51,084] Trial 2 failed with parameters: {'learning_rate': 0.001, 'momentum': 0.99} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/quentin/BigData/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_64730/1486575523.py\", line 24, in objective2\n",
      "    for images, labels in train_loader:\n",
      "  File \"/home/quentin/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/quentin/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 757, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/quentin/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/tmp/ipykernel_64730/2111165720.py\", line 24, in __getitem__\n",
      "    image = self.drawing_to_image(drawing)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_64730/2111165720.py\", line 95, in drawing_to_image\n",
      "    pil_image = pil_image.resize((img_size, img_size), Image.Resampling.LANCZOS)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/quentin/BigData/.venv/lib/python3.12/site-packages/PIL/Image.py\", line 2365, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-13 16:45:51,098] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Run Optuna Study\u001b[39;00m\n\u001b[1;32m     45\u001b[0m study2 \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mstudy2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(study2\u001b[38;5;241m.\u001b[39mbest_params)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(study2\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[23], line 24\u001b[0m, in \u001b[0;36mobjective2\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):  \u001b[38;5;66;03m# Use a small number of epochs for quick evaluation\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m, in \u001b[0;36mQuickDrawDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Convert the drawing format to image\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     drawing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawings\u001b[38;5;241m.\u001b[39miloc[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawings, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrawings[idx]\n\u001b[0;32m---> 24\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawing_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrawing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39miloc[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Convert the image to a tensor and add batch dimension\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 95\u001b[0m, in \u001b[0;36mQuickDrawDataset.drawing_to_image\u001b[0;34m(self, drawing)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Resize to 64x64\u001b[39;00m\n\u001b[1;32m     94\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(cropped_image)\n\u001b[0;32m---> 95\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m \u001b[43mpil_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLANCZOS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(pil_image)\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/PIL/Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2357\u001b[0m         )\n\u001b[1;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2363\u001b[0m         )\n\u001b[0;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam, SGD, RMSprop\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective2(trial):\n",
    "    # Define the search space\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [0.001, 0.0005])\n",
    "    momentum = trial.suggest_categorical(\"momentum\", [0.9, 0.99, 0.5])\n",
    "    \n",
    "    # Initialize model\n",
    "    model = EnhancedCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    # Training loop (simplified for Optuna)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Use a small number of epochs for quick evaluation\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluation (simplified, using validation loss as metric)\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return -total_loss  # Minimize validation loss\n",
    "\n",
    "# Run Optuna Study\n",
    "study2 = optuna.create_study(direction=\"maximize\")\n",
    "study2.optimize(objective2, n_trials=6)\n",
    "\n",
    "\n",
    "print(study2.best_params)\n",
    "print(study2.best_value)\n",
    "optuna.visualization.plot_optimization_history(study2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5981960058933914\n",
      "Epoch 2, Loss: 0.4705312406810587\n",
      "Epoch 3, Loss: 0.4356443354667346\n",
      "Epoch 4, Loss: 0.41511178876122823\n",
      "Epoch 5, Loss: 0.40138269837044027\n",
      "Epoch 6, Loss: 0.3911075291577309\n",
      "Epoch 7, Loss: 0.3823388489897702\n",
      "Epoch 8, Loss: 0.37551491190459185\n",
      "Epoch 9, Loss: 0.36954945308827797\n",
      "Epoch 10, Loss: 0.36413811731490286\n",
      "Accuracy: 90.56%\n",
      "Execution time: 21996.449075 seconds\n",
      "Model saved to final_model.pth\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "train_model(deepModel, optimizer, criterion)\n",
    "test_model(deepModel)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "# Save the trained model to a file\n",
    "model_file_path = \"final_model.pth\"\n",
    "torch.save(deepModel.state_dict(), model_file_path)\n",
    "print(f\"Model saved to {model_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two deeper models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def train_model_with_scheduler(model, optimizer, scheduler, criterion, num_epochs=10):\n",
    "    print(num_epochs)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(f\"Learning Rate: {param_group['lr']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetLikeCNN structure:\n",
      "ResNetLikeCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (shortcut): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/10], Loss: 0.5782\n",
      "Epoch [2/10], Loss: 0.4584\n",
      "Epoch [3/10], Loss: 0.4262\n",
      "Epoch [4/10], Loss: 0.4053\n",
      "Epoch [5/10], Loss: 0.3914\n",
      "Epoch [6/10], Loss: 0.3814\n",
      "Epoch [7/10], Loss: 0.3732\n",
      "Epoch [8/10], Loss: 0.3651\n",
      "Epoch [9/10], Loss: 0.3596\n",
      "Epoch [10/10], Loss: 0.3542\n",
      "Accuracy: 90.80%\n",
      "Execution time: 14662.274112 seconds\n",
      "Model saved to deeper1_model_dynamic.pth\n"
     ]
    }
   ],
   "source": [
    "class ResNetLikeCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetLikeCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Shortcut connection to match the channel dimensions\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=1),  # Match input to output channels\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d((8, 8))  # Ensure consistent spatial dimensions\n",
    "        self.fc = None  # Placeholder, will be dynamically initialized\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))  # First convolution\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))  # Second convolution\n",
    "        residual = self.shortcut(x)              # Adjust dimensions for residual\n",
    "        x = torch.relu(self.bn3(self.conv3(x)) + residual)  # Add residual to output\n",
    "        x = self.pool(x)  # Downsample to fixed size\n",
    "        x = torch.flatten(x, 1)  # Flatten before fully connected layers\n",
    "        x = self.fc(x)  # Fully connected layers\n",
    "        return x\n",
    "\n",
    "    def initialize_fc(self, input_shape):\n",
    "        # Dynamically calculate the input size of the flattened feature map\n",
    "        dummy_input = torch.zeros(input_shape)  # Create a dummy tensor with input shape\n",
    "        conv_output = self.conv1(dummy_input)  # Pass through layers to determine flattened size\n",
    "        conv_output = torch.relu(self.bn1(conv_output))\n",
    "        conv_output = torch.relu(self.bn2(self.conv2(conv_output)))\n",
    "        residual = self.shortcut(conv_output)\n",
    "        conv_output = torch.relu(self.bn3(self.conv3(conv_output)) + residual)\n",
    "        conv_output = self.pool(conv_output)\n",
    "        flattened_size = torch.flatten(conv_output, 1).shape[1]  # Calculate flattened size\n",
    "        \n",
    "        # Define the fully connected layers dynamically\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "# Define number of classes and input shape\n",
    "input_shape = (1, 1, 64, 64)  # Batch size of 1, 1 channel, 64x64 image size\n",
    "\n",
    "# Instantiate the model and initialize fully connected layers\n",
    "deeper1Model = ResNetLikeCNN(num_classes=num_classes)\n",
    "deeper1Model.initialize_fc(input_shape)\n",
    "\n",
    "# Move model to the device\n",
    "deeper1Model = deeper1Model.to(device)\n",
    "\n",
    "# Define optimizer, scheduler, and criterion\n",
    "optimizer = optim.Adam(deeper1Model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print model structure\n",
    "print(\"ResNetLikeCNN structure:\")\n",
    "print(deeper1Model)\n",
    "\n",
    "# Training and testing\n",
    "start_time = time.time()\n",
    "train_model(deeper1Model, optimizer, scheduler, criterion, num_epochs)\n",
    "test_model(deeper1Model)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "# Save the trained model\n",
    "model_file_path = \"deeper1_model_dynamic.pth\"\n",
    "torch.save(deeper1Model.state_dict(), model_file_path)\n",
    "print(f\"Model saved to {model_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeeperCNN2 structure:\n",
      "DeeperCNN2(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc2): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (fc1): Linear(in_features=8192, out_features=512, bias=True)\n",
      ")\n",
      "Epoch [1/10], Loss: 0.4659\n",
      "Epoch [2/10], Loss: 0.3979\n",
      "Epoch [3/10], Loss: 0.3839\n",
      "Epoch [4/10], Loss: 0.3762\n",
      "Epoch [5/10], Loss: 0.3717\n",
      "Epoch [6/10], Loss: 0.3676\n",
      "Epoch [7/10], Loss: 0.3643\n",
      "Epoch [8/10], Loss: 0.3627\n",
      "Epoch [9/10], Loss: 0.3605\n",
      "Epoch [10/10], Loss: 0.3589\n",
      "Accuracy: 88.95%\n",
      "Execution time: 9541.829543 seconds\n",
      "Model saved to deeper2_model_dynamic.pth\n"
     ]
    }
   ],
   "source": [
    "class DeeperCNN2(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DeeperCNN2, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc1 = None  # Placeholder, will be initialized dynamically\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # Output layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)  # Pass through convolutional layers\n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch size\n",
    "        x = self.fc1(x)  # First fully connected layer\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "    def initialize_fc(self, input_shape):\n",
    "        # Dynamically calculate the input size of the flattened feature map\n",
    "        dummy_input = torch.zeros(input_shape)  # Create a dummy tensor with input shape\n",
    "        conv_output = self.conv_layers(dummy_input)  # Pass through conv layers\n",
    "        flattened_size = torch.flatten(conv_output, 1).shape[1]  # Calculate flattened size\n",
    "        self.fc1 = nn.Linear(flattened_size, 512)  # Initialize fc1 with calculated size\n",
    "\n",
    "\n",
    "input_shape = (1, 1, 64, 64)  # Batch size of 1, 1 channel, 64x64 image size\n",
    "\n",
    "# Instantiate the model and initialize fully connected layer\n",
    "deeper2Model = DeeperCNN2(num_classes=num_classes)\n",
    "deeper2Model.initialize_fc(input_shape)\n",
    "\n",
    "# Move model to the device\n",
    "deeper2Model = deeper2Model.to(device)\n",
    "\n",
    "# Define optimizer, scheduler, and criterion\n",
    "optimizer = optim.Adam(deeper2Model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print model structure\n",
    "print(\"DeeperCNN2 structure:\")\n",
    "print(deeper2Model)\n",
    "\n",
    "# Training and testing\n",
    "start_time = time.time()\n",
    "train_model(deeper2Model, optimizer, scheduler, criterion, num_epochs)\n",
    "test_model(deeper2Model)\n",
    "end_time = time.time()\n",
    "\n",
    "# Print execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "# Save the trained model\n",
    "model_file_path = \"deeper2_model_dynamic.pth\"\n",
    "torch.save(deeper2Model.state_dict(), model_file_path)\n",
    "print(f\"Model saved to {model_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df    word countrycode                 timestamp  recognized key_id  \\\n",
      "0     0          FR  2025-01-17T10:37:48.061Z       False      0   \n",
      "1     0          FR  2025-02-06T13:29:39.990Z       False      0   \n",
      "\n",
      "                                             drawing  \n",
      "0  [[[157, 158, 159, 161, 165, 169, 173, 175, 177...  \n",
      "1  [[[110, 106, 99, 91, 83, 82, 81, 93, 105, 117,...  \n",
      "prediction_dataset <__main__.QuickDrawDataset object at 0x7f2fe1000f80>\n",
      "prediction_loader <torch.utils.data.dataloader.DataLoader object at 0x7f2fe05379e0>\n",
      "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), np.int64(0))\n",
      "Shape :  torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :  torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drawing = [[[232,232,234,234,234,234,234,234,235,235,235,235,235,235,235,235,235,234,234,234,234,234,234,234,234,234,234,234,235,235,235,235,235,235,235,235,235,235,235,235,235,235,234],[393,395,395,396,397,398,400,401,401,402,403,405,406,407,408,410,411,411,412,413,415,416,418,420,421,422,423,425,425,426,427,428,430,431,432,433,435,436,437,438,440,441,441],[0,89,96,104,120,129,137,145,160,168,176,184,192,200,208,216,224,245,253,264,272,295,320,336,353,385,424,449,470,480,504,520,536,553,562,576,584,603,629,708,729,763,777]],[[248,248,249,249,249,249,249,249,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,249,249,249,250,250,250,250,250,250,250,250,251,251,251,251],[398,400,400,401,402,403,405,406,406,407,408,410,411,412,413,415,416,417,418,420,421,422,423,425,426,427,427,428,430,430,431,432,433,435,436,437,438,438,440,441,442],[1433,1545,1552,1561,1569,1577,1586,1600,1608,1616,1624,1644,1656,1677,1688,1711,1719,1745,1755,1778,1803,1811,1836,1849,1882,1905,1913,1936,1962,1986,2002,2027,2052,2084,2116,2187,2211,2219,2235,2261,2393]],[[251,252,254,255,255,256,256,257,259,259,258,258,257,256,256,256,254,254,253,253,252,251,251,249,249,248,248,247,247,246,244,244,243,242,241,241,239,238,238,237,237,236,236,234,234,233,232,232,231,229,229,228,227,227,226,226,224,223,223,224,225,226,226,227,229,229,230,231,232,232,234,235],[442,442,442,442,443,443,445,445,445,446,446,447,447,447,448,450,450,451,452,453,455,455,456,456,457,457,458,458,460,460,460,461,461,461,461,460,460,460,459,459,458,458,457,457,455,455,455,454,453,453,452,452,452,450,450,449,449,449,448,448,447,447,445,445,445,444,444,443,443,442,442,442],[2608,2693,2710,2736,2744,2752,2760,2769,2803,2810,3025,3065,3084,3112,3119,3161,3168,3247,3258,3274,3283,3322,3346,3449,3556,3584,3593,3618,3668,3683,3764,3796,3819,3881,3920,3928,3936,3959,3967,3979,3986,3995,4002,4010,4017,4025,4041,4050,4065,4092,4105,4125,4154,4178,4200,4209,4225,4273,4481,4488,4513,4545,4566,4576,4586,4592,4617,4649,4659,4666,4737,4833]],[[252,252,252,252,252,252,252,251,251],[402,400,399,398,397,395,394,394,393],[5699,5837,5866,5906,5924,5954,5986,6136,6180]],[[251,252,254,255,256,257,259,260,261,261,262,264,265,266,267,269,270,270,271,272,274,274,275,276,277,279,279,280,281,281,281,282,282,284,284,283,282,282,281,279,278,277,277,276],[393,393,393,393,393,393,393,393,393,392,392,392,392,392,392,392,392,390,390,389,389,388,388,385,385,384,383,383,382,380,379,379,378,378,377,377,377,375,375,374,374,374,373,373],[6776,6904,6945,6964,6973,6985,6993,7001,7023,7059,7065,7073,7081,7106,7154,7161,7181,7189,7197,7250,7257,7280,7289,7297,7305,7314,7328,7336,7355,7427,7434,7441,7449,7457,7481,7764,7772,7787,7797,7822,7847,7858,7866,7914]],[[276,276,276,276,274,273,273,272,272,271,271,272,274,274,275,275,274,273,272,271,269,269,268,268,268,268,267,266,266,266,264,264,264,263,263,262,262,261,259,258,258,257,256,256,254,253,252,251,249,248,247,246,244,243,243,242,241,239,238,237,232,227,226,224,223,222,221,219,218,217,217,216,214,213,213,212,212,211,208,208,207,207,207,209,209,210,210,209,209,208,207,206,206,207,209,209,210,211,211,211,211,211,211,212,212,214,215,216,216,217,219,219,220,221,221,222,222,224,224,225,226,227,229,230,231,232,234,235],[373,372,370,369,369,369,368,368,367,367,365,364,364,363,363,362,360,360,359,359,359,358,358,360,361,362,362,362,363,365,365,366,367,367,368,368,370,370,370,371,372,372,372,373,373,373,373,373,375,375,375,375,375,374,375,375,375,376,376,376,376,376,376,376,376,376,376,376,375,375,374,374,373,373,372,372,370,370,370,371,371,372,373,373,375,375,376,376,377,377,377,377,378,378,378,380,380,380,381,382,383,385,386,386,387,387,387,387,388,388,388,390,390,390,391,391,392,392,393,393,393,393,393,393,393,393,393,393],[8768,9048,9137,9448,9497,9537,9545,9560,9568,9586,9595,9977,9988,10105,10112,10120,10417,10473,10479,10544,10576,10587,10977,10985,11000,11057,11064,11088,11099,11119,11127,11163,11172,11179,11202,11218,11244,11252,11265,11273,11298,11306,11327,11335,11344,11352,11364,11396,11419,11427,11482,11510,11521,11530,11537,11546,11553,11561,11569,11577,11585,11593,11601,11610,11618,11666,11714,11754,11810,11818,11850,11876,11890,11897,11904,11912,11920,11928,12026,12761,12833,12900,13216,13273,13337,13344,13366,13588,13617,13756,13848,13864,14016,14073,14088,14112,14119,14141,14208,14377,14409,14472,14521,14745,14765,14773,14825,14848,14856,14872,14913,14953,14973,15016,15051,15082,15090,15130,15145,15173,15211,15234,15293,15315,15340,15379,15445,15465]],[[232,234,235,236,237,239,240,241,242,244,245,246,247,249,250,251,252],[397,397,397,397,397,397,397,397,397,397,397,397,397,397,397,397,397],[16944,17136,17153,17178,17191,17248,17270,17295,17344,17376,17409,17428,17475,17495,17506,17581,17674]],[[234,234,234,234,234,234,234,234,234,234,234,234,234,234,234,234,234,234,234],[377,375,374,373,372,370,369,368,367,365,364,363,362,360,359,358,357,355,354],[20138,20306,20339,20368,20378,20403,20427,20451,20483,20506,20534,20547,20576,20603,20626,20635,20642,20657,20676]],[[252,251,251,251,251,249,249,249,249,249,249,249,249,248,248,248,248,249,249,249,249,249],[376,375,374,373,372,372,370,369,368,367,365,364,363,363,362,360,359,359,358,357,355,354],[22167,22267,22274,22299,22314,22330,22338,22358,22370,22399,22442,22465,22522,22541,22553,22586,22661,22682,22715,22738,22787,22808]],[[234,234,233,233,232,231,231,229,228,228,227,227,226,224,224,224,225,225,226,226,226,226,227,229,229,230,230,231,231],[355,354,354,353,353,352,350,350,350,349,349,348,348,348,347,345,344,343,342,340,339,338,337,337,335,335,334,334,333],[23498,23619,23648,23656,23665,23689,23722,23756,23764,23777,23798,23834,23868,23889,24072,24097,24122,24135,24160,24200,24248,24272,24570,24577,24618,24666,24688,24697,24713]],[[252,252,252,254,254,255,255,256,257,257,259,258,258,258,258,258,258,258,258,258,257,257,256,254,253,253,252],[355,354,353,353,352,352,350,350,350,349,349,349,348,347,345,344,343,342,340,339,339,338,338,338,338,337,337],[25599,25800,25807,25832,25854,25864,25921,25928,25953,25962,25991,26291,26299,26323,26347,26371,26395,26435,26454,26479,26744,26761,26776,26824,26865,26963,26987]],[[232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,231,231,231,231,231,231,231,231,231,229,229,229,229,230,230,230,230,230,230,230,230,230,230,230,230,230,230,230,230,231,231,231,231,231,231,231,232,232,232,232,232,232,232,234,234,234,235,235,236,236,236,237,237,239,238,239,240,240,241],[334,333,332,330,329,328,327,325,324,323,322,320,319,318,317,315,314,313,312,310,309,308,307,305,305,304,303,302,297,295,294,293,292,292,287,285,284,284,283,282,280,279,278,277,275,274,273,272,270,269,268,267,265,265,264,263,262,260,259,258,258,257,255,254,253,252,250,250,249,248,248,247,247,245,244,244,243,243,242,242,242,240,240],[27727,27872,27896,27936,27960,27985,27999,28024,28031,28088,28136,28167,28188,28210,28244,28258,28268,28277,28285,28347,28368,28376,28417,28428,28435,28443,28451,28460,28468,28476,28510,28518,28577,28591,28599,28624,28631,28639,28647,28680,28687,28694,28717,28726,28776,28791,28817,28826,28866,28922,28955,28986,29011,29018,29061,29085,29115,29143,29154,29244,29251,29259,29284,29309,29322,29351,29379,29451,29466,29515,29543,29551,29563,29584,29620,29634,29754,29761,29769,29777,29801,29849,29883]],[[256,256,256,256,256,256,256,256,256,254,254,254,254,254,253,253,253,253,253,253,253,253,253,252,252,252,252,252,252,252,252,252,252,252,252,252,252,252,252,251,251,251,251,251,249,249,249,249,249,249,249,249,249,249,249,249,249,249,249,249,249,249,248,248,248,248,248,248,248,248,248,247,247,247,247,246,246,246,246,246,246,246,246,244,243,243,242,241,239],[340,339,338,337,335,334,333,332,330,330,329,328,327,325,325,324,323,322,320,319,318,317,315,314,313,312,310,309,308,307,305,304,303,302,300,299,298,297,295,295,294,293,292,290,289,288,287,285,284,283,282,280,279,278,277,275,274,273,272,270,269,268,268,267,265,264,263,262,260,259,258,258,257,255,254,254,253,252,250,249,248,247,245,245,245,244,244,244,244],[31199,31256,31283,31323,31347,31366,31391,31399,31424,31449,31474,31482,31498,31515,31524,31532,31546,31565,31590,31615,31625,31648,31657,31682,31691,31704,31723,31748,31759,31781,31806,31815,31840,31872,31896,31914,31927,31952,31976,31983,32006,32015,32040,32056,32081,32095,32120,32127,32151,32173,32186,32207,32235,32266,32291,32315,32330,32416,32439,32448,32464,32496,32528,32535,32556,32581,32608,32631,32655,32680,32712,32739,32747,32760,32781,32792,32800,32822,32830,32839,32847,32855,32864,33000,33022,33047,33055,33112,33123]],[[108],[115],[43729]]]\n",
    "import ujson as json\n",
    "\n",
    "# df = download_data_and_parse_it(\"data/prediction.json\")\n",
    "destination_path = \"data/prediction.json\"\n",
    "if os.path.exists(destination_path):\n",
    "    with open(destination_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                df = pd.DataFrame.from_records(json.load(f))\n",
    "\n",
    "print(\"df\",df)\n",
    "prediction_dataset = QuickDrawDataset(df[\"drawing\"], df[\"word\"], resize_to=(64, 64))\n",
    "print(\"prediction_dataset\",prediction_dataset)\n",
    "prediction_loader = DataLoader(prediction_dataset, batch_size=1, shuffle=True)\n",
    "print(\"prediction_loader\",prediction_loader)\n",
    "drawing = prediction_dataset.__getitem__(0)\n",
    "drawing2 = prediction_dataset.__getitem__(1)\n",
    "\n",
    "print(prediction_loader.dataset[0])\n",
    "print(\"Shape : \", drawing[0].shape)\n",
    "plt.imshow(drawing[0].squeeze(), cmap='gray')  # Squeeze to remove the single channel dimension\n",
    "plt.axis('off')  # Hide axis for better visualization\n",
    "plt.title(drawing[1])\n",
    "plt.show()\n",
    "print(\"Shape : \", drawing2[0].shape)\n",
    "plt.imshow(drawing2[0].squeeze(), cmap='gray')  # Squeeze to remove the single channel dimension\n",
    "plt.axis('off')  # Hide axis for better visualization\n",
    "plt.title(drawing2[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79495/4260353792.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"deepest_model64.pth\", map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'deepest_model64.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# reconstructed_image = prediction_dataset.drawing_to_image(drawing)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# plt.imshow(reconstructed_image, cmap='gray')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plt.axis('off')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m EnhancedCNN()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepest_model64.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# # Prepare the input image\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # Assuming reconstructed_image is a PIL Image\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# transform = ToTensor()  # Convert PIL image to tensor\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# input_image = transform(reconstructed_image).unsqueeze(0)  # Add batch dimension\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/BigData/.venv/lib/python3.12/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'deepest_model64.pth'"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# reconstructed_image = prediction_dataset.drawing_to_image(drawing)\n",
    "# plt.imshow(reconstructed_image, cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "model = EnhancedCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"deepest_model64.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# # Prepare the input image\n",
    "# # Assuming reconstructed_image is a PIL Image\n",
    "# transform = ToTensor()  # Convert PIL image to tensor\n",
    "# input_image = transform(reconstructed_image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():  # No need to compute gradients for inference\n",
    "    for images, labels in prediction_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = model(images)\n",
    "        # print(output)\n",
    "        predicted_class = word_class_mapping[torch.argmax(output, dim=1).item()]\n",
    "        print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "# Print the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9056077539928309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     29051\n",
      "           1       0.89      0.92      0.91     61411\n",
      "           2       0.89      0.91      0.90     25865\n",
      "           3       0.94      0.95      0.95     25256\n",
      "           4       0.94      0.95      0.94     36420\n",
      "           5       0.84      0.81      0.82     24571\n",
      "           6       0.74      0.84      0.79     30525\n",
      "           7       0.83      0.81      0.82     25193\n",
      "           8       0.94      0.91      0.92     26944\n",
      "           9       0.92      0.94      0.93     23984\n",
      "          10       0.87      0.88      0.88     23938\n",
      "          11       0.94      0.94      0.94     27163\n",
      "          12       0.95      0.94      0.94     24589\n",
      "          13       0.85      0.79      0.82     24391\n",
      "          14       0.90      0.89      0.90     24526\n",
      "          15       0.93      0.93      0.93     27049\n",
      "          16       0.94      0.91      0.93     27430\n",
      "          17       0.89      0.89      0.89     24629\n",
      "          18       0.96      0.95      0.96     25225\n",
      "          19       0.91      0.90      0.91     26189\n",
      "          20       0.94      0.92      0.93     28996\n",
      "          21       0.92      0.92      0.92     24888\n",
      "          22       0.96      0.93      0.94     25358\n",
      "\n",
      "    accuracy                           0.91    643591\n",
      "   macro avg       0.91      0.90      0.91    643591\n",
      "weighted avg       0.91      0.91      0.91    643591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = EnhancedCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"final_model.pth\", map_location=torch.device('cpu'), weights_only=True))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def predict_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    model = model.to(device)  # Move the model to the correct device\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to the same device\n",
    "            outputs = model(images)  # Forward pass\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())  # Collect predictions\n",
    "            true_labels.extend(labels.cpu().numpy())    # Collect true labels (optional)\n",
    "    \n",
    "    return predictions, true_labels\n",
    "\n",
    "\n",
    "\n",
    "predictions, true_labels = predict_model(model, test_loader, device)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(true_labels, predictions)}\")\n",
    "print(classification_report(true_labels, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
